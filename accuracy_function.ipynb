{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_accuracy",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbEBapWmuXtY"
      },
      "source": [
        "# Accuracy Function Description\n",
        "\n",
        "This notebook contains 2 metrics to measure accuracy:\n",
        "\n",
        "**1) Index Matching: checking if each note that needs to be played occurs at the correct pitch and duration.**\n",
        "\n",
        "**2) Window Matching: checking if each note that needs to be played occurs within a user-specified window (window size is a parameter) with the correct pitch and duration.**\n",
        "\n",
        "# Function:\n",
        "```\n",
        "accuracy_window(prediction, label, window_size)\n",
        "```\n",
        "\n",
        "The input arguments are as follows:\n",
        "\n",
        "\n",
        "```\n",
        "#prediction: a 2D tensor of dimension 88 × 620 \n",
        "#label: a 2D tensor of dimension 88 × 620\n",
        "#window_size: an **odd positive integer** in which the column of interest is the middle of the window. \n",
        "\n",
        "The default is 1 (for index to index matching) \n",
        "Therefore, if we want perfect index matching, we do not need to set an argument for the window_size\n",
        "\n",
        "#note: for the prediction and label arrays, we have 88 rows to represent the 88 keys in which each column represents the notes being played during each frame (620 frames) \n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzLem2xe2XXA"
      },
      "source": [
        "import torch \n",
        "import numpy as np"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHVgISxBDSWn"
      },
      "source": [
        "def accuracy(prediction, label, window_size = 1):\n",
        "  #initialize count\n",
        "  count = 0\n",
        "  #check if window_size is an integer\n",
        "  #convert each 2D tensor into a 2D numpy array\n",
        "  pred_np = prediction.numpy()\n",
        "  label_np = label.numpy() \n",
        "  #check that the dimensions of the prediction and the label are the same\n",
        "  if pred_np.shape != label_np.shape:\n",
        "    print(\"Error- prediction and label sizes don't match!\")\n",
        "    return\n",
        "  #check that window_size is a positive odd integer \n",
        "  if window_size <= 0:\n",
        "    print(\"Error- window_size is not positive!\")\n",
        "    return\n",
        "  elif isinstance(window_size, int) != True:\n",
        "    print(\"Error- window_size is not an integer!\")\n",
        "    return\n",
        "  elif isinstance(window_size, int) == True:\n",
        "    if window_size % 2 == 0:\n",
        "      print(\"Error- window_size is not odd!\")\n",
        "      return\n",
        "  #find the number of frames of each file\n",
        "  col = pred_np.shape[1]\n",
        "  #check if the values in each column of the prediction are the same for the label within the window_size\n",
        "  for i in range(col):\n",
        "    #case where window_size is out of bounds (beginning case)\n",
        "    if i >=0 and i < int(window_size/2):\n",
        "      lower_lim = 0\n",
        "      upper_lim = i + int(window_size/2)\n",
        "    #case where window_size is out of bounds (end case)\n",
        "    elif i >= col - int(window_size/2) and i <= col:\n",
        "      lower_lim = i - int(window_size/2)\n",
        "      upper_lim = col - 1\n",
        "    else:\n",
        "      lower_lim = i - int(window_size/2)\n",
        "      upper_lim = i + int(window_size/2)\n",
        "    window_arr = label_np[:, lower_lim:upper_lim + 1]\n",
        "    if (np.transpose(pred_np)[i:i+1].tolist()[0] in np.transpose(window_arr).tolist()) == True: \n",
        "      count += 1\n",
        "  return count/col"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xbs3l4XWI7H",
        "outputId": "621faa6a-cb88-439f-8cd6-00cc29fec644"
      },
      "source": [
        "accuracy(a, b)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKsY56AOWbYR"
      },
      "source": [
        "Additional function that works but is not required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6CLxwCuuTEt"
      },
      "source": [
        "def accuracy_idx(prediction, label):\n",
        "  #convert each 2D tensor into a 2D numpy array\n",
        "  pred_np = prediction.numpy()\n",
        "  label_np = label.numpy()\n",
        "  #check that the dimensions of the prediction and the label are the same\n",
        "  if pred_np.shape != label_np.shape:\n",
        "    print(\"Error- prediction and label sizes don't match!\")\n",
        "    return\n",
        "  #find the number of frames of each file\n",
        "  col = pred_np.shape[1]\n",
        "  #check if the values in each column of the prediction are the same for the label\n",
        "  acc_bool = np.all(pred_np == label_np, axis = 0)\n",
        "  count = sum(acc_bool)\n",
        "  return (count/col)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjUT52G0V5Gd"
      },
      "source": [
        "# Some Test Cases (can ignore)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lajjY4RG5Q-H",
        "outputId": "bc2b0550-6fcb-4509-96ff-0c870835f3a4"
      },
      "source": [
        "a = [[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24], [25, 26, 27, 28, 29, 30]]\n",
        "print(a)\n",
        "a = torch.tensor(a)\n",
        "print(a)\n",
        "\n",
        "#b = [[0, 1, 4, 0, 0, 3], [0, 7, 10, 0, 0, 9], [0, 13, 16, 0, 0, 15], [0, 19, 22, 0, 0, 21], [0, 25, 28, 0, 0, 27]]\n",
        "b = [[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24], [25, 26, 27, 28, 29, 30]]\n",
        "print(b)\n",
        "b = torch.tensor(b)\n",
        "print(b)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24], [25, 26, 27, 28, 29, 30]]\n",
            "tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12],\n",
            "        [13, 14, 15, 16, 17, 18],\n",
            "        [19, 20, 21, 22, 23, 24],\n",
            "        [25, 26, 27, 28, 29, 30]])\n",
            "[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24], [25, 26, 27, 28, 29, 30]]\n",
            "tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12],\n",
            "        [13, 14, 15, 16, 17, 18],\n",
            "        [19, 20, 21, 22, 23, 24],\n",
            "        [25, 26, 27, 28, 29, 30]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzN_Ze7L2pqn",
        "outputId": "2976bd90-3f18-409b-8717-dd401d537ccf"
      },
      "source": [
        "a = torch.ones(5, 7, dtype=torch.int16)\n",
        "print(a)\n",
        "b = torch.zeros(5, 7, dtype=torch.int16)\n",
        "print(b)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1]], dtype=torch.int16)\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0]], dtype=torch.int16)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}