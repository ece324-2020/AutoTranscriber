{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from torch import nn \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basicNet(nn.Module): \n",
    "    def __init__(self, num_kernels=40):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            # input batchsizex1x229x626\n",
    "            nn.Conv2d(1, 10, (3, 3), padding=1),\n",
    "            nn.BatchNorm2d(10), \n",
    "            nn.ReLU(), \n",
    "            # current shape batchsizex229x10x626\n",
    "            nn.Conv2d(10, 10, (3, 3), padding=1), \n",
    "            nn.BatchNorm2d(10), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d((4, 1)), \n",
    "            nn.Dropout(0.25), \n",
    "            # current shape batchsizex57x626x10\n",
    "            nn.Conv2d(10, 20, (3, 3), padding=1), \n",
    "            nn.BatchNorm2d(20), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d((4, 1)), \n",
    "            nn.Dropout(0.25), \n",
    "            # current shape 14x626x20\n",
    "        )\n",
    "    \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((626*20*14), 3130),\n",
    "            nn.Dropout(0.5),\n",
    "            # Code calls for another batch norm here but unsure what to specifically normalize here\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=626, hidden_size=626) # hidden_size is num of features \n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear((626*5), 626*3), \n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        print(batch_size)\n",
    "        print(x.shape)\n",
    "        x = self.cnn(x)\n",
    "        print(x.shape)\n",
    "        x = x.transpose(1, 3).flatten(-3)\n",
    "        print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(batch_size, 5, 626) \n",
    "        print(x.shape)\n",
    "        a, x = self.rnn(x)\n",
    "        print(x.shape)\n",
    "        print(a.shape)\n",
    "        x = x.transpose(1, 2).flatten(-2)\n",
    "        print(x.shape)\n",
    "        print(a.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(batch_size, 3, 626)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([10, 1, 229, 626])\n",
      "torch.Size([10, 20, 14, 626])\n",
      "torch.Size([10, 175280])\n",
      "torch.Size([10, 3130])\n",
      "torch.Size([10, 5, 626])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([10, 5, 626])\n",
      "torch.Size([1, 3130])\n",
      "torch.Size([10, 5, 626])\n",
      "torch.Size([1, 1878])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 3, 626]' is invalid for input of size 1878",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-d4c963e85523>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m626\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasicNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-203-76c9e15704b2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m626\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[10, 3, 626]' is invalid for input of size 1878"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(10, 1, 229, 626)\n",
    "inp2 = torch.randn(1, 626, 14*40)\n",
    "model = basicNet()\n",
    "res = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "torch.Size([2, 1, 229, 626])\n",
      "torch.Size([2, 20, 14, 626])\n",
      "torch.Size([2, 175280])\n",
      "torch.Size([2, 3130])\n",
      "torch.Size([2, 5, 626])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([2, 5, 626])\n",
      "torch.Size([1, 3130])\n",
      "torch.Size([2, 5, 626])\n",
      "torch.Size([1, 1878])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 10, 229, 626]             100\n",
      "       BatchNorm2d-2         [-1, 10, 229, 626]              20\n",
      "              ReLU-3         [-1, 10, 229, 626]               0\n",
      "            Conv2d-4         [-1, 10, 229, 626]             910\n",
      "       BatchNorm2d-5         [-1, 10, 229, 626]              20\n",
      "              ReLU-6         [-1, 10, 229, 626]               0\n",
      "         MaxPool2d-7          [-1, 10, 57, 626]               0\n",
      "           Dropout-8          [-1, 10, 57, 626]               0\n",
      "            Conv2d-9          [-1, 20, 57, 626]           1,820\n",
      "      BatchNorm2d-10          [-1, 20, 57, 626]              40\n",
      "             ReLU-11          [-1, 20, 57, 626]               0\n",
      "        MaxPool2d-12          [-1, 20, 14, 626]               0\n",
      "          Dropout-13          [-1, 20, 14, 626]               0\n",
      "           Linear-14                 [-1, 3130]     548,629,530\n",
      "          Dropout-15                 [-1, 3130]               0\n",
      "          Sigmoid-16                 [-1, 3130]               0\n",
      "              GRU-17  [[-1, 5, 626], [-1, 5, 626]]               0\n",
      "           Linear-18                 [-1, 1878]       5,880,018\n",
      "          Sigmoid-19                 [-1, 1878]               0\n",
      "================================================================\n",
      "Total params: 554,512,458\n",
      "Trainable params: 554,512,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.55\n",
      "Forward/backward pass size (MB): 15.43\n",
      "Params size (MB): 2115.30\n",
      "Estimated Total Size (MB): 2131.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 229, 626))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 229, 626])\n",
      "torch.Size([1, 1, 626, 229])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 229, 626)\n",
    "print(x.shape)\n",
    "print(torch.transpose(x, 2, 3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4273,  0.4385, -0.4127,  ..., -0.3558,  0.9284, -1.0684],\n",
      "          [-0.9351, -0.6404, -1.0334,  ...,  1.0659,  0.5425, -0.8897],\n",
      "          [ 0.5311, -1.0317, -0.9953,  ...,  1.0791,  0.7940, -0.8141],\n",
      "          ...,\n",
      "          [-0.0255, -0.4855,  1.0145,  ...,  0.0353,  0.1047, -0.2250],\n",
      "          [ 1.0807,  1.8722,  0.5847,  ..., -1.1226,  0.6154,  0.4500],\n",
      "          [-0.4431, -0.0150,  1.6142,  ..., -0.7368, -1.1152, -0.0807]]]])\n",
      "torch.Size([1, 1, 229, 626])\n",
      "tensor([[[[ 0.4273, -0.9351,  0.5311,  ..., -0.0255,  1.0807, -0.4431],\n",
      "          [ 0.4385, -0.6404, -1.0317,  ..., -0.4855,  1.8722, -0.0150],\n",
      "          [-0.4127, -1.0334, -0.9953,  ...,  1.0145,  0.5847,  1.6142],\n",
      "          ...,\n",
      "          [-0.3558,  1.0659,  1.0791,  ...,  0.0353, -1.1226, -0.7368],\n",
      "          [ 0.9284,  0.5425,  0.7940,  ...,  0.1047,  0.6154, -1.1152],\n",
      "          [-1.0684, -0.8897, -0.8141,  ..., -0.2250,  0.4500, -0.0807]]]])\n",
      "torch.Size([1, 1, 626, 229])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 1, 229, 626)\n",
    "print(inp)\n",
    "print(inp.shape)\n",
    "inpMod = inp.transpose(2, 3)\n",
    "print(inpMod) \n",
    "print(inpMod.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1345,  0.0615, -0.6616, -0.1899, -1.1562],\n",
      "        [-2.2821, -1.1816,  1.9076, -0.0721, -0.5117],\n",
      "        [-0.1722, -1.5611, -1.5708,  1.9354,  1.4404],\n",
      "        ...,\n",
      "        [ 1.6196,  0.7744, -0.1988,  0.2942,  0.4754],\n",
      "        [ 0.9557, -0.1949, -0.0298,  0.5104,  0.8935],\n",
      "        [ 0.2450,  1.1709, -1.4639, -1.0854, -0.9646]])\n",
      "torch.Size([626, 5])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(1, 3130)\n",
    "x2 = x1.reshape(626, 5)\n",
    "print(x2)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basicNetMk2(nn.Module): \n",
    "    def __init__(self, num_kernels=40):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            # input batchsizex1x229x626\n",
    "            nn.Conv2d(1, 10, (3, 3), padding=1),\n",
    "            nn.BatchNorm2d(10), \n",
    "            nn.ReLU(), \n",
    "            # current shape batchsizex229x10x626\n",
    "            nn.Conv2d(10, 10, (3, 3), padding=1), \n",
    "            nn.BatchNorm2d(10), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d((4, 1)), \n",
    "            nn.Dropout(0.25), \n",
    "            # current shape batchsizex57x626x10\n",
    "            nn.Conv2d(10, 20, (3, 3), padding=1), \n",
    "            nn.BatchNorm2d(20), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d((4, 1)), \n",
    "            nn.Dropout(0.25), \n",
    "            # current shape 14x626x20\n",
    "        )\n",
    "    \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((626*20*14), 3130),\n",
    "            nn.Dropout(0.5),\n",
    "            # Code calls for another batch norm here but unsure what to specifically normalize here\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=626, hidden_size=626)\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear((626*5), 626*3), \n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        print(\"hello!\")\n",
    "        print(x.shape)\n",
    "        x = self.cnn(x)\n",
    "        print(x.shape)\n",
    "        x = x.transpose(1, 3).flatten(-3)\n",
    "        print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(batch_size, 5, 626) \n",
    "        print(x.shape)\n",
    "        a, x = self.rnn(x)\n",
    "        print(x.shape)\n",
    "        print(a.shape)\n",
    "        x = x.transpose(1, 2).flatten(-2)\n",
    "        print(x.shape)\n",
    "        print(a.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(batch_size, 3, 626)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "torch.Size([1, 1, 229, 626])\n",
      "torch.Size([1, 20, 14, 626])\n",
      "torch.Size([1, 175280])\n",
      "torch.Size([1, 3130])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 3130])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 1878])\n",
      "torch.Size([1, 3, 626])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 1, 229, 626)\n",
    "model = basicNetMk2()\n",
    "res = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "torch.Size([2, 1, 1, 229, 626])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [10, 1, 3, 3], but got 5-dimensional input of size [2, 1, 1, 229, 626] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-f644f0dde450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m229\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m626\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-187-d70e4eaeae0c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hello!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ece324\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 415\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [10, 1, 3, 3], but got 5-dimensional input of size [2, 1, 1, 229, 626] instead"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 229, 626))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ece324] *",
   "language": "python",
   "name": "conda-env-ece324-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
