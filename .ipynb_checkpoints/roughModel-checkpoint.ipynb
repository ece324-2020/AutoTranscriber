{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from torch import nn \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basicNet(nn.Module): \n",
    "    def __init__(self, num_kernels=40):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            # input 229x626\n",
    "            nn.Conv2d(1, 10, (3, 3), padding=1),\n",
    "            nn.BatchNorm2d(10), \n",
    "            nn.ReLU(), \n",
    "            # current shape 229x10x626\n",
    "            nn.Conv2d(10, 10, (3, 3), padding=1), \n",
    "            nn.BatchNorm2d(10), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d((4, 1)), \n",
    "            nn.Dropout(0.25), \n",
    "            # current shape 57x626x10\n",
    "            nn.Conv2d(10, 20, (3, 3), padding=1), \n",
    "            nn.BatchNorm2d(20), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d((4, 1)), \n",
    "            nn.Dropout(0.25), \n",
    "            # current shape 14x626x20\n",
    "        )\n",
    "    \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((626*20*14), 3130),\n",
    "            nn.Dropout(0.5),\n",
    "            # Code calls for another batch norm here but unsure what to specifically normalize here\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=626, hidden_size=626)\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear((626*5), 626*3), \n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        print(\"hello!\")\n",
    "        print(x.shape)\n",
    "        x = self.cnn(x)\n",
    "        print(x.shape)\n",
    "        x = x.transpose(1, 3).flatten(-3)\n",
    "        print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(batch_size, 5, 626) \n",
    "        print(x.shape)\n",
    "        a, x = self.rnn(x)\n",
    "        print(x.shape)\n",
    "        print(a.shape)\n",
    "        x = x.transpose(1, 2).flatten(-2)\n",
    "        print(x.shape)\n",
    "        print(a.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "torch.Size([1, 1, 229, 626])\n",
      "torch.Size([1, 20, 14, 626])\n",
      "torch.Size([1, 175280])\n",
      "torch.Size([1, 3130])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 3130])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([1, 1878])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 1, 229, 626)\n",
    "inp2 = torch.randn(1, 626, 14*40)\n",
    "model = basicNet()\n",
    "res = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "torch.Size([2, 1, 229, 626])\n",
      "torch.Size([2, 20, 14, 626])\n",
      "torch.Size([2, 175280])\n",
      "torch.Size([2, 3130])\n",
      "torch.Size([2, 5, 626])\n",
      "torch.Size([1, 5, 626])\n",
      "torch.Size([2, 5, 626])\n",
      "torch.Size([1, 3130])\n",
      "torch.Size([2, 5, 626])\n",
      "torch.Size([1, 1878])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 10, 229, 626]             100\n",
      "       BatchNorm2d-2         [-1, 10, 229, 626]              20\n",
      "              ReLU-3         [-1, 10, 229, 626]               0\n",
      "            Conv2d-4         [-1, 10, 229, 626]             910\n",
      "       BatchNorm2d-5         [-1, 10, 229, 626]              20\n",
      "              ReLU-6         [-1, 10, 229, 626]               0\n",
      "         MaxPool2d-7          [-1, 10, 57, 626]               0\n",
      "           Dropout-8          [-1, 10, 57, 626]               0\n",
      "            Conv2d-9          [-1, 20, 57, 626]           1,820\n",
      "      BatchNorm2d-10          [-1, 20, 57, 626]              40\n",
      "             ReLU-11          [-1, 20, 57, 626]               0\n",
      "        MaxPool2d-12          [-1, 20, 14, 626]               0\n",
      "          Dropout-13          [-1, 20, 14, 626]               0\n",
      "           Linear-14                 [-1, 3130]     548,629,530\n",
      "          Dropout-15                 [-1, 3130]               0\n",
      "          Sigmoid-16                 [-1, 3130]               0\n",
      "              GRU-17  [[-1, 5, 626], [-1, 5, 626]]               0\n",
      "           Linear-18                 [-1, 1878]       5,880,018\n",
      "          Sigmoid-19                 [-1, 1878]               0\n",
      "================================================================\n",
      "Total params: 554,512,458\n",
      "Trainable params: 554,512,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.55\n",
      "Forward/backward pass size (MB): 15.43\n",
      "Params size (MB): 2115.30\n",
      "Estimated Total Size (MB): 2131.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 229, 626))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 229, 626])\n",
      "torch.Size([1, 1, 626, 229])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 229, 626)\n",
    "print(x.shape)\n",
    "print(torch.transpose(x, 2, 3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4273,  0.4385, -0.4127,  ..., -0.3558,  0.9284, -1.0684],\n",
      "          [-0.9351, -0.6404, -1.0334,  ...,  1.0659,  0.5425, -0.8897],\n",
      "          [ 0.5311, -1.0317, -0.9953,  ...,  1.0791,  0.7940, -0.8141],\n",
      "          ...,\n",
      "          [-0.0255, -0.4855,  1.0145,  ...,  0.0353,  0.1047, -0.2250],\n",
      "          [ 1.0807,  1.8722,  0.5847,  ..., -1.1226,  0.6154,  0.4500],\n",
      "          [-0.4431, -0.0150,  1.6142,  ..., -0.7368, -1.1152, -0.0807]]]])\n",
      "torch.Size([1, 1, 229, 626])\n",
      "tensor([[[[ 0.4273, -0.9351,  0.5311,  ..., -0.0255,  1.0807, -0.4431],\n",
      "          [ 0.4385, -0.6404, -1.0317,  ..., -0.4855,  1.8722, -0.0150],\n",
      "          [-0.4127, -1.0334, -0.9953,  ...,  1.0145,  0.5847,  1.6142],\n",
      "          ...,\n",
      "          [-0.3558,  1.0659,  1.0791,  ...,  0.0353, -1.1226, -0.7368],\n",
      "          [ 0.9284,  0.5425,  0.7940,  ...,  0.1047,  0.6154, -1.1152],\n",
      "          [-1.0684, -0.8897, -0.8141,  ..., -0.2250,  0.4500, -0.0807]]]])\n",
      "torch.Size([1, 1, 626, 229])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 1, 229, 626)\n",
    "print(inp)\n",
    "print(inp.shape)\n",
    "inpMod = inp.transpose(2, 3)\n",
    "print(inpMod) \n",
    "print(inpMod.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1345,  0.0615, -0.6616, -0.1899, -1.1562],\n",
      "        [-2.2821, -1.1816,  1.9076, -0.0721, -0.5117],\n",
      "        [-0.1722, -1.5611, -1.5708,  1.9354,  1.4404],\n",
      "        ...,\n",
      "        [ 1.6196,  0.7744, -0.1988,  0.2942,  0.4754],\n",
      "        [ 0.9557, -0.1949, -0.0298,  0.5104,  0.8935],\n",
      "        [ 0.2450,  1.1709, -1.4639, -1.0854, -0.9646]])\n",
      "torch.Size([626, 5])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(1, 3130)\n",
    "x2 = x1.reshape(626, 5)\n",
    "print(x2)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ece324] *",
   "language": "python",
   "name": "conda-env-ece324-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
